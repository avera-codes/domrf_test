{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemiy/domrf_test/domrf_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "import faiss\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/artemiy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"papers.csv\")\n",
    "df = df.dropna(subset=[\"Title\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для генерации эмбеддингов\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для генерации инструкций\n",
    "instruction_model_name = \"google/flan-t5-base\"\n",
    "instruction_tokenizer = AutoTokenizer.from_pretrained(instruction_model_name)\n",
    "instruction_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    instruction_model_name\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для ответа на вопросы\n",
    "qa_model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, batch_size=16):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        inputs = embedding_tokenizer(\n",
    "            batch_texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_instructional_question(question):\n",
    "    instructional_keywords = [\"how\", \"steps\", \"procedure\", \"process\", \"implement\", \"deploy\"]\n",
    "    return any(word in question.lower() for word in instructional_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_answer(question):\n",
    "    input_text = f\"Summarize the steps for {question}\"\n",
    "    inputs = instruction_tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = instruction_model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "    return instruction_tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_tokenize(text):\n",
    "    blocks = text.split(\"\\n\\n\")\n",
    "    sentences = []\n",
    "    for block in blocks:\n",
    "        tokenized = nltk.sent_tokenize(block)\n",
    "        combined = []\n",
    "        i = 0\n",
    "        while i < len(tokenized):\n",
    "            if re.match(r\"^\\d+\\.?$\", tokenized[i]):\n",
    "                if i + 1 < len(tokenized):\n",
    "                    combined.append(f\"{tokenized[i]} {tokenized[i + 1]}\")\n",
    "                    i += 2\n",
    "                else:\n",
    "                    combined.append(tokenized[i])\n",
    "                    i += 1\n",
    "            else:\n",
    "                combined.append(tokenized[i])\n",
    "                i += 1\n",
    "        sentences.extend(combined)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences\"] = df[\"Text\"].apply(split_and_tokenize)\n",
    "sentences = df.explode(\"sentences\").reset_index(drop=True)\n",
    "sentence_embeddings = get_embeddings(sentences[\"sentences\"].tolist()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексирование с помощью FAISS\n",
    "index = faiss.IndexFlatL2(sentence_embeddings.shape[1])\n",
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relevant_sentences(question, k=5):\n",
    "    question_embedding = get_embeddings([question]).detach().numpy()\n",
    "    distances, indices = index.search(question_embedding, k)\n",
    "    return sentences.iloc[indices[0]][\"sentences\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(question, context):\n",
    "    inputs = qa_tokenizer(question, context, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = qa_model(**inputs)\n",
    "    start_idx = torch.argmax(outputs.start_logits)\n",
    "    end_idx = torch.argmax(outputs.end_logits) + 1\n",
    "    answer = qa_tokenizer.convert_tokens_to_string(\n",
    "        qa_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_idx:end_idx])\n",
    "    )\n",
    "    return answer.strip(), outputs.start_logits.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_answer(answer):\n",
    "    if answer:\n",
    "        return answer[0].upper() + answer[1:]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    if is_instructional_question(question):\n",
    "        relevant_sentences = search_relevant_sentences(question, k=3)\n",
    "        combined_context = \" \".join(relevant_sentences)\n",
    "        instruction_answer = generate_instruction_answer(\n",
    "            f\"{question}. {combined_context}\"\n",
    "        )\n",
    "        return format_answer(instruction_answer)\n",
    "\n",
    "    relevant_sentences = search_relevant_sentences(question)\n",
    "    answers = [extract_answer(question, sentence) for sentence in relevant_sentences]\n",
    "\n",
    "    filtered_answers = [ans for ans in answers if ans[0]]\n",
    "    if not filtered_answers:\n",
    "        return \"Ответ не найден\"\n",
    "\n",
    "    best_answer = max(filtered_answers, key=lambda x: x[1])\n",
    "    return format_answer(best_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Where can I apply Convolutional Neural Network?\",\n",
    "    \"What is Reinforcement Learning?\",\n",
    "    \"How to deploy a machine learning model?\",\n",
    "    \"How to implement a random forest algorithm?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"Where can I apply Convolutional Neural Network?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"What is Reinforcement Learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"How to deploy a machine learning model?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question4 = \"How to implement a random forest algorithm?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing, classification, segmentation and also for other auto\n",
      "correlated data\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(answer_question(question1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem faced by an agent( a program) that must learn behavior\n",
      "through trial and error interactions with a dynamic environment to\n",
      "maximize some reward\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(answer_question(question2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy a machine learning application into a production environment.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(answer_question(question3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a random forest model. Build a Random Forest Classifier.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(answer_question(question4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Where can I apply Convolutional Neural Network?\n",
      "Ответ: Image processing, classification, segmentation and also for other auto correlated data\n",
      "\n",
      "Вопрос: What is Reinforcement Learning?\n",
      "Ответ: The problem faced by an agent( a program) that must learn behavior through trial and error interactions with a dynamic environment to maximize some reward\n",
      "\n",
      "Вопрос: How to deploy a machine learning model?\n",
      "Ответ: Deploy a machine learning application into a production environment.\n",
      "\n",
      "Вопрос: How to implement a random forest algorithm?\n",
      "Ответ: Create a random forest model. Build a Random Forest Classifier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    print(f\"Вопрос: {question}\\nОтвет: {answer_question(question)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domrf_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
